"""
Black Vault â€” Ingestion pipeline.
Read text file â†’ verify MIME â†’ chunk â†’ embed â†’ store.
"""

from __future__ import annotations

import mimetypes
from pathlib import Path
from google import genai
from langchain_text_splitters import RecursiveCharacterTextSplitter

from backend.config import GEMINI_API_KEY, EMBEDDING_MODEL, CHUNK_SIZE, CHUNK_OVERLAP
from backend import db


_client: genai.Client | None = None


def _genai() -> genai.Client:
    global _client
    if _client is None:
        _client = genai.Client(api_key=GEMINI_API_KEY)
    return _client


def get_embedding(text: str) -> list[float]:
    """Get the embedding vector for a single text string."""
    result = _genai().models.embed_content(
        model=EMBEDDING_MODEL,
        contents=text,
    )
    return list(result.embeddings[0].values)


def get_embeddings_batch(texts: list[str]) -> list[list[float]]:
    """Get embeddings for a batch of texts in a single API call."""
    if not texts:
        return []
    result = _genai().models.embed_content(
        model=EMBEDDING_MODEL,
        contents=texts,
    )
    return [list(e.values) for e in result.embeddings]


def detect_mime(path: str) -> str:
    """Detect MIME type using built-in mimetypes."""
    mime_type, _ = mimetypes.guess_type(path)
    return mime_type or "application/octet-stream"


def ingest_file(path: str) -> int:
    """
    Ingest a text file into Black Vault.

    1. Verify it's a text file (MIME type text/*)
    2. Read contents
    3. Chunk with RecursiveCharacterTextSplitter
    4. Embed each chunk via Gemini
    5. Store item + content + embeddings in DuckDB
    6. Trigger enrichment & connection finding

    Returns the new item id.
    """
    filepath = Path(path).resolve()
    if not filepath.exists():
        raise FileNotFoundError(f"File not found: {filepath}")

    # â”€â”€ 1. MIME check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    mime = detect_mime(str(filepath))
    if not mime.startswith("text/"):
        raise ValueError(
            f"Unsupported file type: {mime}. "
            f"MVP only supports text/* files."
        )

    # â”€â”€ 2. Read â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    text = filepath.read_text(encoding="utf-8")
    if not text.strip():
        raise ValueError("File is empty.")

    # â”€â”€ 3. Chunk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        length_function=len,
        is_separator_regex=False,
    )
    chunks = splitter.split_text(text)
    print(f"ðŸ“„ {filepath.name}: {len(chunks)} chunk(s)")

    # â”€â”€ 4. Embed â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    vectors = get_embeddings_batch(chunks)

    # â”€â”€ 5. Store â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    item_id = db.insert_item(source_path=str(filepath), source_type="text")

    for i, (chunk, vec) in enumerate(zip(chunks, vectors)):
        content_id = db.insert_content(item_id=item_id, chunk_index=i, body=chunk)
        db.insert_embedding(content_id=content_id, item_id=item_id, vector=vec)

    # Rebuild HNSW index after inserting new vectors
    db.create_hnsw_index()

    print(f"âœ… Stored as item #{item_id}")

    # â”€â”€ 6. Enrichment & connections (inline for MVP) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    from backend.enrich import enrich_item
    from backend.connections import find_connections

    enrich_item(item_id)
    find_connections(item_id)

    return item_id
